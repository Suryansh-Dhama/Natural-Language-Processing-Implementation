{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26d2ce3f-f1b4-4fe6-bf6a-d0e10791eef8",
   "metadata": {},
   "source": [
    "# STEMMING\n",
    "Stemming is the process of reducing a word to its word stem that affixes to suffixes and prefixes or to the roots of words known as a lemma. Stemming is important in natural language understanding (NLU) and natural language processing (NLP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e0e38bc-efd0-46f6-9000-90b57b098f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92f879f9-ff06-4f87-8fd0-a3bde49d179e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemming = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa3a57b8-53f0-4faf-8b30-727750c9ed02",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"eating\",\"eats\",\"eaten\",\"writing\",\"writes\",\"programming\",\"programs\",\"history\",\"finally\",\"finalized\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "242aabc9-732e-43bf-bc6e-6cb10aca57f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating - eat\n",
      "eats - eat\n",
      "eaten - eaten\n",
      "writing - write\n",
      "writes - write\n",
      "programming - program\n",
      "programs - program\n",
      "history - histori\n",
      "finally - final\n",
      "finalized - final\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word,\"-\",stemming.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dad918da-158e-479a-a65b-45c220ee5a61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'congratul'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem('congratulated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc01867c-20e4-47dd-a594-1b0429f2e8c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'understand'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem('understanding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "786b919a-9531-4672-a508-060c4daa0a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sit'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem('sitting')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68a7b85-0acc-4c16-8d1d-0b9fdd546fab",
   "metadata": {},
   "source": [
    "# LANCASTER STEMMING ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "096d7f8a-c151-4576-92e0-9e16896f8c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5660a4c3-9f4e-42a0-9ac5-4cdd354f8624",
   "metadata": {},
   "outputs": [],
   "source": [
    "lancaster = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f17db61-0b9d-4c00-b2f3-794cc85909b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating - eat\n",
      "eats - eat\n",
      "eaten - eat\n",
      "writing - writ\n",
      "writes - writ\n",
      "programming - program\n",
      "programs - program\n",
      "history - hist\n",
      "finally - fin\n",
      "finalized - fin\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word,\"-\",lancaster.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca45e1b-28dd-422e-a452-d95f8e1576e0",
   "metadata": {},
   "source": [
    "# RegexpStemmer class\n",
    "NLTK has RegexpStemmer class with the help of which we can easily implement Regular Expression Stemmer algorithms. It basically takes a single regular expression and removes any prefix or suffix that matches the expression. Let us see an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aedc3ffd-240c-4636-9dd3-35397dc3e448",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import RegexpStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75f482aa-a633-4f17-90e6-c8fe2e80c69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_stemmer = RegexpStemmer('ing|s$|e$|able$', min = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c376ca33-bdf7-44be-9643-c13e00da9580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemmer.stem('eating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "383ebb9e-f1c8-40ab-9d0d-a46d018e7c8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'play'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemmer.stem('ingplaying')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c29404-2da8-4878-9c5e-8300459fab0a",
   "metadata": {},
   "source": [
    "# SNOWBALL STEMMER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0eb54f2-1c35-40b3-b220-6c5731aafbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1de758db-80cd-4f2a-a55a-4b695a4411ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowballstemmer = SnowballStemmer('english',ignore_stopwords=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c80588c6-4a56-4970-82dc-187d24a508b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating - eat\n",
      "eats - eat\n",
      "eaten - eaten\n",
      "writing - write\n",
      "writes - write\n",
      "programming - program\n",
      "programs - program\n",
      "history - histori\n",
      "finally - final\n",
      "finalized - final\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word,\"-\",snowballstemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f43a8e8-a2ee-44bb-a95a-842c2b56f78c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fairli', 'sportingli')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem(\"fairly\"),stemming.stem(\"sportingly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0568734-632c-4920-a5c9-02220fc5ddc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fair', 'sport')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowballstemmer.stem(\"fairly\"),snowballstemmer.stem(\"sportingly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3bc849-df3c-404a-856e-2e994fb84222",
   "metadata": {},
   "source": [
    "# WORDNET LEMMATIZER\n",
    "Lemmatization technique is like stemming. The output we will get after lemmatization is called ‘lemma’, which is a root word rather than root stem, the output of stemming. After lemmatization, we will be getting a valid word that means the same thing.\n",
    "\n",
    "NLTK provides WordNetLemmatizer class which is a thin wrapper around the wordnet corpus. This class uses morphy() function to the WordNet CorpusReader class to find a lemma. Let us understand it with an example −"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94a00761-37fe-47d2-8cb6-7665202aaeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7130dab3-86fc-4b7b-90a0-39e7591af5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating - eat\n",
      "eats - eat\n",
      "eaten - eat\n",
      "writing - write\n",
      "writes - write\n",
      "programming - program\n",
      "programs - program\n",
      "history - history\n",
      "finally - finally\n",
      "finalized - finalize\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "POS- Noun-n\n",
    "Verb-v\n",
    "Adjective-a\n",
    "Adverb-r\n",
    "'''\n",
    "for word in words:\n",
    "    print(word,\"-\",lemmatizer.lemmatize(word,pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "caeac77f-ec54-4e82-bc21-06cb6c4cea3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating - eating\n",
      "eats - eats\n",
      "eaten - eaten\n",
      "writing - writing\n",
      "writes - writes\n",
      "programming - programming\n",
      "programs - programs\n",
      "history - history\n",
      "finally - finally\n",
      "finalized - finalized\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word,\"-\",lemmatizer.lemmatize(word,pos='a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42c0c153-21d7-4f17-80d0-3563e081f34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating - eating\n",
      "eats - eats\n",
      "eaten - eaten\n",
      "writing - writing\n",
      "writes - writes\n",
      "programming - programming\n",
      "programs - programs\n",
      "history - history\n",
      "finally - finally\n",
      "finalized - finalized\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word,\"-\",lemmatizer.lemmatize(word,pos='r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a5e287a-502e-487a-a6ef-82bb2122daee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'better'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"better\",pos='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "103087b3-26d5-4ac9-856e-47bd58ed9fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'good'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"good\",pos='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe7c022b-4b15-47e3-a5d8-6adecca403d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'best'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"best\",pos='v')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
